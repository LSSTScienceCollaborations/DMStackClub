{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the LSST Stack Multiband Deblender \n",
    "<br>Owner(s): **Fred Moolekamp** ([@fred3m](https://github.com/LSSTScienceCollaborations/StackClub/issues/new?body=@fred3m))\n",
    "<br>Last Verified to Run: **2018-08-17**\n",
    "<br>Verified Stack Release: **w_2018_32**\n",
    "\n",
    "This tutorial is designed to illustrate how to execute the multiband deblender (*scarlet*) in the LSST stack. This includes a brief introduction to LSST stack objects including:\n",
    "\n",
    " - Geometry classes from `lsst.geom`, such as points and boxes.\n",
    " - Higher-level astronomical primitives from `lsst.afw`, such as the `Image`, `Exposure`, and `Psf` classes.\n",
    " - Our core algorithmic `Task` classes, including those for source detection, deblending, and measurement.\n",
    " \n",
    "We'll be working with coadded images made from Subaru Hyper Suprime-Cam (HSC) data in the COSMOS field.  We've taken a recent LSST reprocessing of the HSC-SSP UltraDeep COSMOS field (see [this page](https://confluence.lsstcorp.org/display/DM/S18+HSC+PDR1+reprocessing) for information on that reprocessing, and [this page](https://hsc-release.mtk.nao.ac.jp/doc/) for the data), and added simulated stars from a scaled [SDSS catalog](http://www.sdss.org/dr14/data_access/value-added-catalogs/?vac_id=photometry-of-crowded-fields-in-sdss-for-galactic-globular-and-open-clusters).  The result is a very deep image (deeper than the 10-year LSST Deep-Wide-Fast survey, though not as deep as LSST Deep Drilling fields will be) with both a large number of galaxies and region full of stars.\n",
    "\n",
    "This tutorial is based on Jim Bosch's globular cluster tutorial, however in it's present state *scarlet* is unable to process the crowded field (most likely) due to poor initial conditions for the sources in the field. So instead we use a region of the image outside of the cluster.\n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "After working through this tutorial you should be able to: \n",
    "1. Configure and run the LSST multiband deblender on a test list of objects;\n",
    "2. Understand its task context in the DRP pipeline.\n",
    "\n",
    "### Logistics\n",
    "This notebook is intended to be runnable on `lsst-lspdev.ncsa.illinois.edu` from a local git clone of https://github.com/LSSTScienceCollaborations/StackClub.\n",
    "\n",
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We'll start with some standard imports of both LSST and third-party packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lsst.daf.persistence import Butler\n",
    "from lsst.geom import Box2I, Box2D, Point2I, Point2D, Extent2I, Extent2D\n",
    "from lsst.afw.image import Exposure, Image, PARENT, MultibandExposure, MultibandImage\n",
    "from lsst.afw.detection import MultibandFootprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "We'll be retrieving data using the `Butler` tool, which manages where various datasets are stored on the filesystem (and can in principle manage datasets that aren't even stored as files, though all of these are).\n",
    "\n",
    "We start by creating a `Butler` instance, pointing it at a *Data Repository* (which here is just a root directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butler = Butler(\"/project/jbosch/tutorials/lsst2018/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets managed by a butler are identified by a dictionary *Data ID* (specifying things like the visit number or sky patch) and a string *DatasetType* (such as a particular image or catalog).  Different DatasetTypes have different keys, while different instances of the same Dataset Type have different values.  All of the datasets we use in this tutorial will correspond to the same patch of sky, so they'll have at least the keys in the dictionary in the next cell (they will also have `filter`, but with different values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataId = {\"tract\": 9813, \"patch\": \"4,4\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use those to load a set of *grizy* coadds, which we'll put directly in a dictionary.  The result of each `Butler.get` call is in this case an `lsst.afw.image.Exposure` object, an image that actually contains three \"planes\" (the main image, a bit mask, and a variance image) as well as many other objects that describe the image, such as its PSF and WCS.  Note that we (confusingly) use `Exposures` to hold coadd images as well as true single-exposure images, but combine them into a `MultibandExposure`, which contains an exposure in each band.\n",
    "\n",
    "The DatasetType here is `deepCoadd_calexp` (a coadd on which we've already done some additional processing, such as subtracting the background and setting some mask values), and the extra `filter` argument gets appended to the Data ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = \"grizy\"\n",
    "coadds = [butler.get(\"deepCoadd_calexp\", dataId, filter=\"HSC-{}\".format(f.upper())) for f in filters]\n",
    "coadds = MultibandExposure.fromExposures(filters, coadds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making and displaying color composite images\n",
    "\n",
    "We'll start by just looking at the images, as 3-color composites.  We'll use astropy to build those as a nice way to demonstrate how to get NumPy arrays from the `MultibandImage` objects (the images in `coadds`).  (LSST also has code to make 3-color composites using the same algorithm, and in fact the Astropy implementation is based on ours, but now that it's in Astropy we'll probably retire ours.)\n",
    "\n",
    "We'll just use matplotlib to display the images themselves.  We'll use Firefly for other image display tasks later, but while Firefly itself supports color-composites, work on our preferred composition algorithm is still in progress, and we haven't quite finished connecting that functionality to the Python client we'll demonstrate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.visualization import make_lupton_rgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the following function a few times to display color images.  It's worth reading through the implementation carefully to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showRGB(image, bgr=\"gri\", ax=None, fp=None, figsize=(8,8), stretch=1, Q=10):\n",
    "    \"\"\"Display an RGB color composite image with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : `MultibandImage`\n",
    "        `MultibandImage` to display.\n",
    "    bgr : sequence\n",
    "        A 3-element sequence of filter names (i.e. keys of the exps dict) indicating what band\n",
    "        to use for each channel. If `image` only has three filters then this parameter is ignored\n",
    "        and the filters in the image are used.\n",
    "    ax : `matplotlib.axes.Axes`\n",
    "        Axis in a `matplotlib.Figure` to display the image.\n",
    "        If `axis` is `None` then a new figure is created.\n",
    "    fp: `lsst.afw.detection.Footprint`\n",
    "        Footprint that contains the peak catalog for peaks in the image.\n",
    "        If `fp` is `None` then no peak positions are plotted.\n",
    "    figsize: tuple\n",
    "        Size of the `matplotlib.Figure` created.\n",
    "        If `ax` is not `None` then this parameter is ignored.\n",
    "    stretch: int\n",
    "        The linear stretch of the image.\n",
    "    Q: int\n",
    "        The Asinh softening parameter.\n",
    "    \"\"\"\n",
    "    # If the image only has 3 bands, reverse the order of the bands to produce the RGB image\n",
    "    if len(image) == 3:\n",
    "        bgr = image.filters\n",
    "    # Extract the primary image component of each Exposure with the .image property, and use .array to get a NumPy array view.\n",
    "    rgb = make_lupton_rgb(image_r=image[bgr[2]].array,  # numpy array for the r channel\n",
    "                          image_g=image[bgr[1]].array,  # numpy array for the g channel\n",
    "                          image_b=image[bgr[0]].array,  # numpy array for the b channel\n",
    "                          stretch=stretch, Q=Q)  # parameters used to stretch and scale the pixel values\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    # Exposure.getBBox() returns a Box2I, a box with integer pixel coordinates that correspond to the centers of pixels.\n",
    "    # Matplotlib's `extent` argument expects to receive the coordinates of the edges of pixels, which is what\n",
    "    # this Box2D (a box with floating-point coordinates) represents.\n",
    "    integerPixelBBox = image[bgr[0]].getBBox()\n",
    "    bbox = Box2D(integerPixelBBox)\n",
    "    ax.imshow(rgb, interpolation='nearest', origin='lower', extent=(bbox.getMinX(), bbox.getMaxX(), bbox.getMinY(), bbox.getMaxY()))\n",
    "    if fp is not None:\n",
    "        for peak in fp.getPeaks():\n",
    "            ax.plot(peak.getIx(), peak.getIy(), \"bx\", mew=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can slice `MultibandImage` objects (as well a `MultibandExposure` objects) along the filter dimension using the filter names as indices. Like `Exposure` objects, `MultibandExposure` objects have `image`, `mask`, and `variance` properties that contain the image, mask plane, and variance of the `Exposure` respectively. For now we will only worry about the `image` property, although internal deblending and measurement algorithms make use of all three objects (when available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showRGB(coadds[:\"z\"].image, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showRGB(coadds[\"i\":].image, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those images are a full \"patch\", which is our usual unit of processing for coadds - it's about the same size as a single LSST sensor (exactly the same in pixels, smaller in terms of area because these use HSC's smaller pixel scale).  That's a bit unweildy (just because waiting for processing to happen isn't fun in a tutorial setting), so we'll reload our dict with sub-images centered on the region of interest.\n",
    "\n",
    "Note that we can load the sub-images directly with the `butler`, by appending `_sub` to the DatasetType and passing a `bbox` argument. If you want to see the region of the image with the cluster, use `clusterBBox` below, however as mentioned above, that region is too memory intensive for the current version of *scarlet*. Instead use `sampleBBox` to select a sub-region of the image (note that we add a small frame around each blend to include more background regions, which are important for the detection algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 50\n",
    "clusterBBox = Box2I(Point2I(18325, 17725), Extent2I(400, 350))\n",
    "\n",
    "#sampleBBox = Box2I(Point2I(18699-frame, 17138-frame), Extent2I(93+2*frame, 104+2*frame))\n",
    "#sampleBBox = Box2I(Point2I(16424-frame, 17806-frame), Extent2I(55+2*frame, 62+2*frame))\n",
    "#sampleBBox = Box2I(Point2I(17838-frame, 18945-frame), Extent2I(111+2*frame, 103+2*frame))\n",
    "sampleBBox = Box2I(Point2I(19141-frame, 18228-frame), Extent2I(63+2*frame, 87+2*frame))\n",
    "\n",
    "subset = coadds[:, sampleBBox]\n",
    "# Due to a bug in the code the PSF isn't copied properly.\n",
    "# The code below copies the PSF into the `MultibandExposure`,\n",
    "# but will be unecessary in the future\n",
    "for f in subset.filters:\n",
    "    subset[f].setPsf(coadds[f].getPsf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showRGB(subset.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Processing\n",
    "\n",
    "Now we'll try the regular LSST processing tasks, with a simpler configuration than we usually use to process coadds, just to avoid being distracted by complexity.  This includes\n",
    "\n",
    " - Detection (`SourceDetectionTask`): given an `Exposure`, find above-threshold regions and peaks within them (`Footprints`), and create a *parent* source for each `Footprint`.\n",
    " - Deblending (`MultibandDeblendTask`): given a `MultibandExposure` and a catalog of parent sources, create a *child* source for each peak in every `Footprint` that contains more than one peak.  Each child source is given a `HeavyFootprint`, which contains both the pixel region that source covers and the fractional pixel values associated with that source. A `SourceDeblendTask` is also available using the single band SDSS-HSC deblender that takes a single band `Exposure`).\n",
    " - Measurment (`SingleFrameMeasurementTask`): given an `Exposure` and a catalog of sources, run a set of \"measurement plugins\" on each source, using deblended pixel values if it is a child. Notice that measurement is still performed on single band catalogs, since none of the measurement algorithms work for multiband data.\n",
    "\n",
    "We'll start by importing these, along with the `SourceCatalog` class we'll use to hold the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.meas.algorithms import SourceDetectionTask\n",
    "from lsst.meas.deblender import MultibandDeblendTask\n",
    "from lsst.meas.base import SingleFrameMeasurementTask\n",
    "from lsst.afw.table import SourceCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now construct all of these `Tasks` before actually running any of them.  That's because `SourceDeblendTask` and `SingleFrameMeasurementTask` are constructed with a `Schema` object that records what fields they'll produce, and they modify that schema when they're constructed by adding columns to it.  When we run the tasks later, they'll need to be given a catalog that includes all of those columns, **but we can't add columns to a catalog that already exists**.\n",
    "\n",
    "To recap, the sequence looks like this:\n",
    "\n",
    " 1. Make a (mostly) empty schema.\n",
    " 2. Construct all of the `Task`s (in the order you plan to run them), which adds columns to the schema.\n",
    " 3. Make a `SourceCatalog` object from the *complete* schema.\n",
    " 4. Pass the same `SourceCatalog` object to each `Task` when you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = SourceCatalog.Table.makeMinimalSchema()\n",
    "\n",
    "detectionTask = SourceDetectionTask(schema=schema)\n",
    "\n",
    "config = MultibandDeblendTask.ConfigClass()\n",
    "config.usePsfConvolution = True\n",
    "config.conserveFlux = True\n",
    "config.maxIter = 100\n",
    "deblendTask = MultibandDeblendTask(schema=schema, config=config)\n",
    "\n",
    "# We'll customize the configuration of measurement to just run a few plugins.\n",
    "# The default list of plugins is much longer (and hence slower).\n",
    "measureConfig = SingleFrameMeasurementTask.ConfigClass()\n",
    "measureConfig.plugins.names = [\"base_SdssCentroid\", \"base_PsfFlux\", \"base_SkyCoord\"]\n",
    "# \"Slots\" are aliases that provide easy access to certain plugins.\n",
    "# Because we're not running the plugin these slots refer to by default,\n",
    "# we need to disable them in the configuration.\n",
    "measureConfig.slots.apFlux = None\n",
    "measureConfig.slots.instFlux = None\n",
    "measureConfig.slots.shape = None\n",
    "measureConfig.slots.modelFlux = None\n",
    "measureConfig.slots.calibFlux = None\n",
    "measureTask = SingleFrameMeasurementTask(config=measureConfig, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step we'll run is detection, which actually returns a new `SourceCatalog` object rather than working on an existing one.\n",
    "\n",
    "Instead, it takes a `Table` object, which is sort of like a factory for records.  We won't use it directly after this, and it isn't actually necessary to make a new `Table` every time you run `MultibandDetectionTask` (but you can only create one after you're done adding columns to the schema).\n",
    "\n",
    "`Task`s that return anything do so via a `lsst.pipe.base.Struct` object, which is just a simple collection of named attributes.  The only return values we're  interested is `sources`.  That's our new `SourceCatalog`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = SourceCatalog.Table.make(schema)\n",
    "detectionResult = detectionTask.run(table, subset[\"r\"])\n",
    "catalog = detectionResult.sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at what's in that catalog.  First off, we can look at its schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this includes a lot of columns that were actually added by the deblend or measurement steps; those will all still be blank (`0` for integers or flags, `NaN` for floating-point columns).\n",
    "\n",
    "In fact, the only columns filled by `SourceDetectionTask` are the IDs.  But it also attaches `Footprint` objects, which don't appear in the schema.  You can retrieve the `Footprint` by calling `getFootprint()` on a row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = catalog[0].getFootprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Footprints` have two components:\n",
    " - a `SpanSet`, which represents an irregular region on an image via a list of (y, x0, x1) `Spans`;\n",
    " - a `PeakCatalog`, a slightly different kind of catalog whose rows represent peaks within that `Footprint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(footprint.getSpans())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(footprint.getPeaks())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we actually look at the footprints in the catalog we see that some have only a single peak, while others have multiple peaks that need to be deblended.\n",
    "\n",
    "To display only the pixels contained in the footprint (and not other pixels in the bounding box) we create a `MultibandFootprint`, which is a `HeavyFootprint` that contains a `SpanSet`, `PeakCatalog`, and `flux` values for all of the pixels in the `SpanSet`. In this case the `flux` is the total measured flux in the image, since no deblending has taken place yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for src in catalog:\n",
    "    fp = src.getFootprint()\n",
    "    img = coadds[:,fp.getBBox()].image\n",
    "    mfp = MultibandFootprint.fromImages(coadds.filters, image=img, footprint=fp)\n",
    "    showRGB(mfp.getImage().image, fp=fp, figsize=(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that while the peaks *can* have both an integer-valued position and a floating-point position, they're the same right now; `SourceDetectionTask` currently just finds the pixels that are local minima and doesn't try to find their sub-pixel locations.  That's left to the centroider, which is part of the measurement stage.\n",
    "\n",
    "Before we can get to that point, we need to run the deblender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxCatalog, templateCatalog = deblendTask.run(coadds, catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MultibandDeblendTask` always returns two catalogs, a `templateCatalog` that contains the model outputs from *scarlet* and a `fluxCatalog`, which uses the *scarlet* models as weights to redistribute the flux from the input image (in other words they contain flux-conserved models). If `MultibandDeblendTask.config.saveTemplates` is `False`, then `templateCatalog` will be `None`. Similarly, if `MultibandDeblendTask.config.conserveFlux` is `False` then the `fluxCatalog` will be `None` (and the code will run slightly faster, since it doesn't have to reweight the flux, however this is a small fraction of the processing time).\n",
    "\n",
    "The deblender itself sets the `parent` column for each source, which is `0` for objects with no parent, and all of the columns that begin with `deblend_` and also adds new rows to the catalog for each child. It does *not* remove the parent rows it created those child rows from, and this is intentional, because we want to measure both \"interpretations\" of the blend family: one in which there is only one object (the parent version) and one in which there are several (the children). Before doing any science with the outputs of an LSST catalog, it's important to remove one of those interpretations (typically the parent one).  That can be done by looking at the `deblend_nChild` and `parent` fields:\n",
    "\n",
    " - `parent` is the ID of the source from which this was deblended, or `0` if the source is itself a parent.\n",
    " - `deblend_nChild` is the number of child sources this source has (so it's `0` for sources that are themselves children or were never blended).\n",
    " \n",
    "Together, these define two particularly useful filters:\n",
    "\n",
    " - `deblend_nChild == 0`: never-blended object or de-blended child\n",
    " - `deblend_nChild == 0 and parent == 0`: never-blended object\n",
    " \n",
    "The first is what you'll usually want to use; the second is what to use if you're willing to throw away some objects (possibly many) because you don't trust the deblender.\n",
    "\n",
    "The last processing step for our purposes is running measurement, which must be done on each catalog, in each band (if we want measurements for all of them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measureTask.run(templateCatalog[\"r\"], coadds['r'])\n",
    "measureTask.run(templateCatalog[\"i\"], coadds['i'])\n",
    "measureTask.run(fluxCatalog[\"r\"], coadds['r'])\n",
    "measureTask.run(fluxCatalog[\"i\"], coadds['i'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to an unfortunate bug in the deblender task, the resulting catalogs are not contiguous and we need to copy them into new objects to use them appropriately. This step can be avoided in the near future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.afw.table as afwTable\n",
    "\n",
    "for f in filters:\n",
    "    _catalog = afwTable.SourceCatalog(templateCatalog[f].table.clone())\n",
    "    _catalog.extend(templateCatalog[f], deep=True)\n",
    "    templateCatalog[f] = _catalog\n",
    "    _catalog = afwTable.SourceCatalog(fluxCatalog[f].table.clone())\n",
    "    _catalog.extend(fluxCatalog[f], deep=True)\n",
    "    fluxCatalog[f] = _catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we care about deblending (for the sake of this tutorial) lets look at the results from the 13th blend displayed above. We use the `HeavyFootprint`s from the catalog sources that have the same parent (parent 13 from above) to build a model for the entre scene, and to compare the results of the flux conserved and *scarlet* models. In the process we look at both the *scarlet* and flux conserved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lsst.afw.detection import MultibandFootprint\n",
    "from lsst.afw.image import MultibandImage\n",
    "\n",
    "# Use the 13th parent in the blend\n",
    "# Note: this is not the parent ID, but the 13th source in the catalog\n",
    "parentIdx = 13\n",
    "\n",
    "# Create empty multiband images to model the entire scene\n",
    "templateModel = MultibandImage.fromImages(coadds.filters,\n",
    "                                          [Image(fluxCatalog[\"r\"][parentIdx].getFootprint().getBBox(), dtype=np.float32)\n",
    "                                           for b in range(len(filters))])\n",
    "fluxModel = MultibandImage.fromImages(coadds.filters,\n",
    "                                          [Image(fluxCatalog[\"r\"][parentIdx].getFootprint().getBBox(), dtype=np.float32)\n",
    "                                           for b in range(len(filters))])\n",
    "\n",
    "# Only use the subset catalogs with the same parent\n",
    "parentId = fluxCatalog[\"r\"][parentIdx].get(\"id\")\n",
    "fluxChildren = {b: fluxCatalog[b][fluxCatalog[b].get(\"parent\")==parentId] for b in filters}\n",
    "templateChildren = {b: templateCatalog[b][templateCatalog[b].get(\"parent\")==parentId] for b in filters}\n",
    "assert(len(fluxChildren)==len(templateChildren))\n",
    "\n",
    "for n in range(len(templateChildren[\"r\"])):\n",
    "    # Add the source model to the model of the entire scene\n",
    "    fp = MultibandFootprint(coadds.filters, [templateChildren[b][n].getFootprint() for b in filters])\n",
    "    _fp = MultibandFootprint(coadds.filters, [fluxChildren[b][n].getFootprint() for b in filters])\n",
    "    templateModel[:, fp.getBBox()].array += fp.getImage(fill=0).image.array\n",
    "    fluxModel[:, _fp.getBBox()].array += _fp.getImage(fill=0).image.array\n",
    "\n",
    "    # Show the model\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    ax = [fig.add_subplot(1, 2, n+1) for n in range(2)]\n",
    "    ax[0].set_title(\"scarlet\")\n",
    "    ax[1].set_title(\"flux conserved\")\n",
    "    showRGB(fp.getImage().image, ax=ax[0])\n",
    "    showRGB(_fp.getImage().image, ax=ax[1])\n",
    "    plt.show()\n",
    "\n",
    "templateResidual = MultibandImage(coadds.filters,\n",
    "                                  coadds[:, templateModel.getBBox()].image.array - templateModel.array)\n",
    "fluxResidual = MultibandImage(coadds.filters,\n",
    "                              coadds[:, fluxModel.getBBox()].image.array - fluxModel.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we look at the full models and the residuals. As expected, there are no residuals for the flux conserved model since all of the flux in the image (that is within the footprint) is added to one of the sources. In this particular case that works fine, but in instances where one or more sources were not detected this can cause one source to have its flux contaminated with its neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, model, residual in [[\"scarlet\", templateModel, templateResidual], [\"flux conserved\", fluxModel, fluxResidual]]:\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "    ax = [fig.add_subplot(1, 2, n+1) for n in range(2)]\n",
    "    ax[0].set_title(\"{0} model\".format(title))\n",
    "    ax[1].set_title(\"{0} residual\".format(title))\n",
    "    showRGB(model, ax=ax[0])\n",
    "    showRGB(residual ,ax=ax[1], Q=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "- Use some of the other`sampleBBox` regions and run through the code again, from source detection through measurment and blending displays. Don't foget to change the parent index to view only the children of the correct blend.\n",
    "- Play around with other *scarlet* constraints, such as adding an L0 penalty. This should help the code execute faster, as one of the main reasons for the slow down is unecessarily large boxes surrounding the smaller sources. See https://github.com/lsst/meas_deblender/blob/master/python/lsst/meas/deblender/deblend.py#L462-L545 for a description of the other configuration options that can be passed to the deblender\n",
    "\n",
    "Note: in order to try out different constraints the `meas_deblender` package requires an upgrade that has not been pushed to master yet. To use the latest changes, from your terminal session you must execute the following steps:\n",
    "\n",
    "```bash\n",
    "~$ cp /project/fred3m/tutorials/lsst2018/.user_setups ~/notebooks\n",
    "~$ source ~/notebooks/.user_setups\n",
    "```\n",
    "\n",
    "You will have to restart the kernel for this notebook session in order for the changes to take place."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
